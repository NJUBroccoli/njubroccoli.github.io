## 绪论

- AI的起源：图灵测试、达特茅斯会议；发展：知识表示和推理（本体和知识图谱）、搜索和剪枝、定理证明的机械化；
- AI的第二次高潮：符号学派的成功：符号和推理、专家系统和知识工程、智慧+；
- AI的第二次低潮：五代机计划的幻灭；
- 后知识工程时代：机器学习、强化学习（奖惩）、迁移学习（复用知识）、主动学习（请oracle解答完善学习）、推荐系统；
- AI的第三次高潮：机器学习的成功；
- AI的第一次冬天：持久的流派之争：符号学派（逻辑）、连接学派（仿生）、行为学派（控制）；
- 大数据时代的人工智能
	+ 大数据的4V特征：海量（Volume）、快速多变（Velocity）、多样性（Variety）、不精确性（Veracity）
	+ 大数据分析的4I特征：近似性（Inexact）、增量性（Incremental）、整合性（Integrated）、归纳性（Inductive）
	+ 大数据分类：多元异构数据、海量分布数据、流数据、交互型数据、图数据

## 搜索

- 状态空间搜索
	+ **图搜索**：需要检测和搜索解路径上的循环
	+ **树搜索**：免除检测的开销
	+ 搜索方向：数据驱动（前向搜索）、目标驱动（后向搜索）
	+ 回溯技术：通过试错方式搜索状态空间所有解路径
	+ **BFS**：FIFO、可保证发现目标状态的最短路径、可能有组合爆炸问题
	+ **DFS**：分析一个节点的兄弟节点之前， 必须分析完所有的孩子节点和其后代；LIFO、不保证发现目标状态的最短路径、可能迷失在搜索空间中
	+ **迭代加深的深度优先搜索**：depth逐渐增大的dfs，与bfs等价
- 启发式搜索
	+ 根据启发值，对OPEN列表中的状态进行排序
	+ **爬山搜索**：扩展当前节点以及其子节点，并进行评估，选择最优的子节点作为下一节点，若当前所有子节点的评估都比当前节点劣，则算法终止. （可增加回溯机制）
	+ **最佳优先搜索**：如何定义启发式估值函数$h(n)$？
		- 8-puzzle问题：错位牌数、错位牌距离和、距离+2*颠倒牌数
		- 当存在相同启发式估值时：$f(n)=g(n)+h(n)$. $g(n)$为搜索次数（深度）

- $A^*$算法
	+ ![](/var/folders/jz/tbj4bmq905d_fsz9n0h3xpqm0000gn/T/TemporaryItems/(A Document Being Saved By screencaptureui 39)/Screen Shot 2019-11-21 at 19.18.26.png)
	+ 以8-puzzle问题为例，$h(n)$可定义为错位牌到正确位置需要移动的格子数目和

- 博弈树搜索
	+ **极小极大过程**：MAX代表我方玩家，最大化收益；MIN代表对手，最小化MAX的收益；MIN总是移动到使MAX收益最坏的状态. 在预判层应用启发式评估，展开所有的后继分支，沿树向上传播评估值.
	+ **极小极大搜索**：将启发值自底向上传播，若父状态是MAX节点，将孩子节点中最大值传给它，若父状态是MIN节点，将孩子节点中最小值传给它.
	+ **固定层深的极小极大过程**（如井字棋）：启发式评估$E(n)=M(n)-O(n)$，其中$M(n)$是当前玩家可能获胜的行数，$O(n)$是对手可能获胜的行数. 利用极小极大倒推求得的当前可做的每一种选择的启发值，来决定MAX的移动.
	+ **$\alpha-\beta$过程**：当确定是一个dead end时，停止展开其后继节点；是对博弈树的DFS，且维护$\alpha$与MAX节点关联，从不减小；$\beta$与MIN节点关联，从不增大.
	+ **$\alpha-\beta$剪枝规则**：任一MIN节点，如果其Beta值小于等于其祖先MAX节点的Alpha值，则停止搜索；任一MAX节点，如果其Alpha值大于等于其祖先MIN节点的Beta值，则停止搜索. 对子节点排序非常敏感.

- 蒙特卡洛树搜索
	+ 基本原理：随机抽样+假设检验+树搜索
	+ 表示：每个节点$m/n$，$m$代表这个子树上赢的次数，$n$代表这个子树上模拟的次数.
	+ 核心四步
		1. 选择：UCT策略，平衡树搜索的广度与深度$$UCT(node)=\frac{W(node)}{N(node)}+\sqrt[c]{\frac{ln(N(parentNode))}{N(node)}}$$
		2. 扩张：添加一个"?"的叶子节点.
		3. 模拟：执行操作，直到达到结束状态，或满足设定的阈值. 基于模拟的结果，建立新添加节点的值.
		4. Backpropagation：利用新添加节点的值，对之前的树进行更新. 从新节点开始，反向遍历到根节点.
	
## 推理

- 自动推理：主要指机器定理证明，核心问题是寻找判定公式是否有效的通用程序.
- **命题演算**
	+ 语法：命题符号（`P, Q, R`）、真值符号（`True, False`）、联结词（`∨，∧，「，→，=`）
	+ 命题表达式等价：两个命题表达式在任何真值指派下都有相同的值.
	+ 推理：推理规则：代换、置换、分离；推理策略：宽度优先、目标驱动.
	+ 子句：文字是原子命题或其否定式，子句是文字的析取. CNF（合取范式）、DNF（析取范式）. 转换DNF方法：一般方法（如德·摩根定律）或真值表方法.

- **谓词演算**
	+ 语法：字母表、项（每一个变量和常数）、原子公式（$R(u_0,u_1,\dots,u_n)$）、公式（若$\varphi,\psi$是公式，则$\neg\varphi,(\varphi),\forall x\varphi,\exists x\varphi, \varphi\vee\psi,\varphi\wedge\psi$也是公式）
	+ 语义：在论域中关系的真假决定了相应表达式的真假. 一个论域$D$上的解释：

	| 常元 | $D$的某个元素 |
	|-----|-----|
   |变元 |$D$的某个非空集集合|
	|$n$元谓词$P$ |$D^n$到$\{T, F\}$的一个映射|
	| $m$元函词$f$ | $D^m$到$D$的一个映射 |
	
- **合一**
	+ 合一：判断什么样的替换可以使两个谓词表达式匹配的算法，表明了多个表达式在什么条件下可以称为等价的.
	+ 替换：将有限个个体变元替换为不同的变元，且新变元不循环出现在原变元集中.
	+ **斯柯伦标准化**：去掉所有的存在量词，如$\exists Z(\mathrm{foo}(Y,Z))$化为$\mathrm{foo}(Y,k)$，$(\forall X)(\exists Y)(\mathrm{mother}(X,Y))$化为$(\forall X)(\mathrm{mother}(X,m(X)))$
	+ 组合：多次替换，最终效果相当于消元.
	+ 最一般的合一式（MGU）：若$g$是表达式$E$的最一般的合一式，则对于任何其它合一式$s$，都存在另一个合一式$s'$，使$Es=Egs'$. 其中$Es$和$Egs'$是应用到表达式$E$的合一式的组合.
	+ 合一算法：讲义上的描述太傻逼了，看例子就懂了.

- **归结**
	+ 基本思想：反证法
	+ **消解**：用最少的合一次数在一个字句数据库中发现矛盾的方法. 具体方法：将已知为真的公理加入集合中$\rightarrow$将所要证的命题取反，加入公理集中$\rightarrow$尝试用消解推理规则（产生空字句）推出矛盾.
	+ **转换子句**：消去蕴含$\rightarrow$将否定式降至原子式$\rightarrow$重命名所有变量标准化$\rightarrow$将所有量词左移$\rightarrow$消除存在量词$\rightarrow$直接去掉所有全称量词$\rightarrow$将表达式转化为CNF$\rightarrow$再次标准化变量（CNF中不同的子句用不同的变量）$\rightarrow$将CNF分为单独的字句
	+ **归结（消解）的策略**
		- 宽度优先策略：时空开销大，保证能发现最短的解路径.
		- 支持策略：要求每次归结的归结式之一至少有一个是由目标公式的否定所得到的子句，或者是它们的后裔. 是完备的策略.
		- 单子句优先策略：只要存在个体子句(一个文字的子句)就是用个体子句归结.

## 知识表示

- 基本概念
	+ 数据：信息的载体和表示；信息：数据的语义；知识：信息关联后所形成的信息结构（事实&规则）；**知识表示**：用来让计算机可以存储和处理知识的模式.
	+ 常见的知识表示方法：一阶谓词表示、产生式表示、语义网络表示、框架表示、脚本表示.

- **一阶谓词表示**
	+ 步骤：定义谓词及变元、变元赋值、连接词连接谓词形成谓词公式.
	+ 以机器人搬盒子为例，定义两类谓词（状态、操作），列出状态谓词合法性（约束条件）和导致的状态变化，最后采用合一和搜索完成规划求解.
	+ 缺陷：丢失了类的继承、关联和因果
	+ 优点：精确、自然、严密、易于实现；缺点：表示和处理分离，组合爆炸导致效率低.

- **产生式表示**
	+ 基本形式：`P -> Q`或`IF P THEN Q`，表示的知识可以是不精确的（可信度），产生式的推理匹配过程可以是部分匹配.
	+ 常用结构：原因$\rightarrow$结果、条件$\rightarrow$结论、前提$\rightarrow$操作、事实$\rightarrow$进展、情况$\rightarrow$行为.
	+ 产生式系统：`数据库 -> 产生式规则库 <-> 推理/控制系统 <-> 数据库`
		- 规则库：有效表达领域内的过程性知识，合理组织与管理知识，提高问题求解效率；
		- 数据库（工作内存）：存放问题求解过程中各种信息的数据结构（初始状态、原始证据、中间结论、最终结论），内容在推理过程中动态变化；
		- 控制系统：从规则库中选择规则与数据库中已知事实匹配，发生冲突时进行消解，若执行规则右部是一个或多个结论，则将结论加入到数据库中；若是一个或多个操作，则执行并将产生的事实加入到数据库中.
	+ 搜索策略：数据驱动（正向推理）、目标驱动（反向推理）、混合驱动（启发式）.
	+ 适用范围：领域中知识单元相互独立，不存在结构关系；具有不确定知识；求解过程可以表示为一系列相对独立的操作，每个操作可以表示为产生式规则.【善于处理过程性的知识】

- **语义网络表示**
	+ **基本网络单元和语义关系**
		- 类属关系：$A\xrightarrow[]{\mathrm{ISA}}B$, $A\xrightarrow[]{\mathrm{A-Member-of}}B$, $A\xrightarrow[]{\mathrm{A-Kind-of}}B$
		- 包含或聚类关系：$A\xrightarrow[]{\mathrm{Part-of}}B$
		- 属性关系：$A\xrightarrow[]{\mathrm{Have}}B$, $A\xrightarrow[]{\mathrm{Can}}B$
		- 时间关系：$A\xrightarrow[]{\mathrm{Before}}B$, $A\xrightarrow[]{\mathrm{After}}B$
		- 推论关系：$A\xrightarrow[]{\textrm{推论}}B$
		- 二元/多元关系：$A \xleftarrow[]{\textrm{主体}} B \xrightarrow[]{\textrm{客体}}C$
	+ 语义网络的推理
		- 继承：把对事物的描述从抽象节点传递到具体节点，通常沿着类属关系ISA, AKO等具有继承关系的边进行.
		- 匹配：把待求解问题构造为网络片段，其中某些节点或边的标识是空的，称为询问点；将网络片段与知识库中的某个语义网络片段进行匹配，则与询问点相匹配的事实就是该问题的解.
	+ 优点：结构性、联想性、自索引性、自然语言的转换性；缺点：不严格性、处理复杂. 本质和谓词演算等价.【善于处理结构性的知识】

- **框架表示**
	+ 定义：描述对象(一个事物、一个事件、一个概念)属性的一种数据结构；在框架表示法中，框架被认为是知识表示的最基本单元.
	+ 表示形式：框架名、槽名(描述某一方面的属性)、侧面(描述属性的某一方面)、值组成
	+ 一般表示形式：

	```
	<框架名>
	槽名1：侧面名11 侧面值111 侧面值112 ... 侧面值11n
	      ...
	      侧面名1m 侧面值1m1 侧面值1m2 ... 侧面值1mn
	...
	槽名k：侧面名k1 侧面值k11 侧面值k12 ... 侧面值k1n
	      ...
	      侧面名ks 侧面值ks1 侧面值ks2 ... 侧面值ksn
	约束条件：约束条件1
	        ...
	        约束条件n
	```
	
	+ 框架网络系统：将多个相互关联的框架连接起来组织的知识表示和推理系统. 纵向联系:通过框架中增加“继承”槽来实现；横向联系:通过槽值或侧面值为另一个框架名.
	+ 优点：结构性(不同于语义网络的结构性)、继承性、自然性；是语义网络的重要扩展；面向对象语言OO的产生. 缺点：缺乏过程性知识表示.
	
## 不确定性推理

- 不确定性推理：从不确定性的初始事实(证据)，运用不确定性的知识，获得不确定性但却合理的结论.
- **反绎推理**（溯因推理）：`(P -> Q) ∧ Q`可能推出P. 是一种寻找最佳解释的推理，不可靠.  
- **基于谓词逻辑的推理**
	+ 三个重要假设：谓词对领域描述是充分的；知识库必须是一致的；应用推理规则得到的信息，必须是单调增长的.
	+ **非单调推理**：基于假设的推理（如何添加基于假设的知识？如何修改不正确的假设？）扩充模态操作符
		- unless操作符：`1. p(x) unless q(x) -> r(x), 2. r(x) -> s(x)` 若`p(W)`成立且不知`q(W)`是否为真，则`r(W)`进而`s(W)`为真；若进一步已知`q(W)`为真，则撤回`r(W), s(W)`. abnormal默认规则：`p(x) unless ab p(x) -> r(x)`.
		- is consistent with操作符
			+ 判定“与……相一致”：可以证明其反，如果不能证明，则与……相一致；也可以在有限空间上做启发式搜索
		- 默认逻辑：`A(x) ∧ : B(x) -> C(x)`. 若A可被证实，且它与对B的假设相一致，则C. 允许产生多个似真的结论；似真的结论可作为公理进一步推理；解决方法:信念变化 -> 回收 -> 知识库一致.
	+ **真值维护系统TMS**
		- 目标：维持推理系统的逻辑完整性；原理：通过存储每条推理的理由，再重新推断根据新的信念所
得出的结论的支持情况；
		- 实现方式：时序回溯（低效）；相关性指导回溯（直接回溯到出问题的点，并在那个状态对解进行修正）
		- **基于理由的真值维护系统JTMS**：理由网络
			+ 结点：知识库中的信念；理由：支持结点上的信念；联系：IN, 支持结点成立的信念集合;OUT, 不支持结点成立的信念集合

	+ **基于最小模型的逻辑**：对所有变量赋值满足谓词表达式S的模型中，最小的那个模型
		- 封闭世界假设：若不含有p(X)为真，那么not(p(X))就为真
		- 限定：“元谓词”划界并限定谓词可能的解释
	+ **集合覆盖**：从规则中寻找观测事实的最小集合覆盖，由此反绎.

- **确信度理论**
	+ Stanford确信度理论：`MB(H|E)`:给定证据E时，假设H的可信度量. `MD(H|E)`:给定证据E时，假设H的不可信度量.
	+ 不确定性知识的表示：`IF E THEN H (CF(H|E))`. 其中`E`是知识的前提条件，`H`是知识的结论，`CF(H|E)`是知识的确信度.
	+ （不）可信度量和概率 $$\mathrm{MB}(H|E)=\left\{\begin{aligned}& 1 & P(H)=1 \\ &\frac{\mathrm{max}\{P(H|E),P(H)\}-P(H)}{1-P(H)} & \mathrm{otherwise}\end{aligned}\right.$$$$\mathrm{MD}(H|E)=\left\{\begin{aligned}& 1 & P(H)=1 \\ &\frac{\mathrm{max}\{P(H|E),P(H)\}-P(H)}{1-P(H)} & \mathrm{otherwise}\end{aligned}\right.$$$$\mathrm{CF}(H|E)=\mathrm{MB}(H|E)-\mathrm{MD}(H|E)$$
		- 若$\mathrm{MB}(H|E)>0$，则$P(H|E)>P(H)$，$E$的出现增加了$H$的概率.
		- 若$\mathrm{MB}(H|E)<0$，则$P(H|E)<P(H)$，$E$的出现增加了$H$的概率.
	+ 确信度性质
		- 互斥性：当$\mathrm{MB}(H|E)>0$时，$\mathrm{MD}(H|E)=0$;当$\mathrm{MD}(H|E)>0$时，$\mathrm{MB}(H|E)=0$.
		- 典型值：当$\mathrm{CF}(H|E)=1$时，有$P(H|E)=1$，$E$的出现使$H$为真. 当$\mathrm{CF}(H|E)=-1$时相应为假.
	+ 证据不确定性的表示
		- 否定：$\mathrm{CF}(\neg E)=-\mathrm{CF}(E)$.
		- 合取：若$E=E_1\mathrm{and}E_2\mathrm{and}\dots\mathrm{and}E_n$，则$\mathrm{CF}(E)=\mathrm{min}\{\mathrm{CF}(E_1),\mathrm{CF}(E_2),\dots,\mathrm{CF}(E_n)\}$.
		- 析取：若$E=E_1\mathrm{or}E_2\mathrm{or}\dots\mathrm{or}E_n$，则$\mathrm{CF}(E)=\mathrm{max}\{\mathrm{CF}(E_1),\mathrm{CF}(E_2),\dots,\mathrm{CF}(E_n)\}$.
	+ 不确定性的更新：$\mathrm{CF}(H)=\mathrm{CF}(H|E)\times\mathrm{max}\{0,\mathrm{CF}(E)\}$.
	+ 结论不确定性的合成：![](/var/folders/jz/tbj4bmq905d_fsz9n0h3xpqm0000gn/T/TemporaryItems/(A Document Being Saved By screencaptureui 41)/Screen Shot 2019-11-22 at 17.38.49.png)

- **证据理论**
	+ DS证据理论：考虑命题集，赋给区间值[belief, plausibility]，每个命题的可信度必须在这个区间内.
	+ 概率密度函数：定义函数$m$，满足$m:2^{\Omega}\rightarrow[0,1]$且$m(\Phi)=0,\sum_{A\subseteq\Omega}m(A)=1$
	+ 信任函数：定义函数$\mathrm{Bel}$，满足$\mathrm{Bel}:2^{\Omega}\rightarrow[0,1],\mathrm{Bel}(A)=\sum_{B\subseteq A}m(B),A\subseteq\Omega$
	+ 似然函数：定义函数$\mathrm{PI}$，满足$\mathrm{PI}:2^{\Omega}\rightarrow[0,1],\mathrm{PI}(A)=1-\mathrm{Bel}(\neg A),A\subseteq\Omega,\neg A=\Omega-A$（非假的信任度）
	+ 两者关系：$\mathrm{PI}(A)\ge\mathrm{Bel}(A)$. 分别称为对$A$信任程度的上下限：$A[\mathrm{Bel}(A),\mathrm{PI}(A)]$. $\mathrm{PI}(A)-\mathrm{Bel}(A)$描述“不知道”的情况.
	+ 证据合并：证据相同时，可信度下限为至少一个可信赖的概率，上限为1；证据相左时，不可能同时信赖，基于此计算两者可信赖的后验概率，得到可信度.
	+ Dempster证据合并规则（前提是证据互相独立）：对于$\forall A\subseteq\Omega$, $\Omega$上的两个函数$m_1,m_2$，其Dempster合成规则为：$$m_1\oplus m_2(A)=\frac{1}{K}\sum_{B\cap C=A}m_1(B)\times m_2(C)$$$$K=\sum_{B\cap C\neq\emptyset}m_1(B)\times m_2(C)=1-\sum_{B\cap C=\emptyset}m_1(B)\times m_2(C)$$

## 贝叶斯网络

- 以前学过的就8记了
- **贝叶斯网络**：有向无环图、节点代表随机变量、边代表因果（用条件概率表达）、无父节点用先验概率表达信息.
- 条件独立性
	+ 顺序连接：`Z -> Y -> X`，给定`Y`则`X, Z`独立，否则不独立.
	+ 分支连接：`Y -> X, Y -> Z`，给定`Y`则`X, Z`独立，否则不独立.
	+ 汇合连接：`X -> Y, Z -> Y`，`Y`未知则`X, Z`独立，否则不独立.
	+ 分支和汇合：`Z -> U -> X, Z -> V -> X`，当且仅当给定`U`和`V`时，`X, Z`独立.

- **$d$-可分**：判断贝叶斯网络中任意两个节点之间是否独立
	+ 定义：$A$和$B$被一组随机变量$E$ $d$-可分，当且仅当他们之间的所有路径都是堵塞的.
	+ **阻塞**：如果$A$到$B$上有这样的一个中间节点$V$，那么路径是堵塞的. $V$满足以下两个属性之一
		- 连接是顺序的或者分支的，$V$在$E$中.
		- 连接是汇合的，则$V$和它的子节点都不在$E$中.

- 贝叶斯网络的构建：定义变量、结构学习、参数学习
- **结构学习**：利用训练样本集，尽可能结合先验知识，确定和训练样本集合匹配最好的贝叶斯网络结构.
	+ 基于搜索和评分的方法：从一个特定的网络出发，利用搜索算法对网络进行操作，根据评分函数对网络进行评分，检查新的网络结构是否优于旧的，如是，则继续.

- **贝叶斯网络的推理**：因果推理（自顶向下）、诊断推理（自底向上）、支持推理（分析原因之间相互影响，如汇合连接）
	+ 因果推理的计算：对于所求的询问节点的条件概率,用所给证据节点和询问节点的所有因节点的联合概率进行重新表达，对所得表达式进行适当变形, 直到其中的所有概率值都可以从问题贝叶斯网络的CPT中得到.
	+ 诊断推理的计算：先利用贝叶斯公式将诊断推理问题转化为因果推理问题; 再用因果推理的结果, 导出诊断推理的结果.

## 马尔科夫网络

- **马尔科夫网**
	+ Markov链：考虑一个$N$(有限)状态$\{s_1,s_2,\dots,s_n\}$的系统，在离散的时间序列中$\{t_1,t_2,\dots\}$，其在时间$t$的状态记为$X_t$. 则$P(X_t=s_k\mid X_1,X_2,\dots,X_{t-1})$. 一阶Markov链：$P(X_t=s_k\mid X_{t-1})$.
	+ Markov网：无向图+概率分布. 一个无向图是Markov网络的充要条件：满足三条**独立性**：
		- Pairwise Markov Property：给定所有其他变量，任意两个不相邻变量条件独立.
		- Local Markov Property：一个变量如果给定所有邻居变量后与所有其他变量条件独立.
		- Global Markov Property：$A$、$B$两个子集间任何一条路径都经过子集$S$，则给定$S$后，$A$、$B$两个子集相互条件独立.
	+ 构建Markov网络：可以基于Pairwise Markov Property或Local Markov Property.

- **马尔科夫逻辑网**
	+ Markov网+一阶逻辑，本质是公式附加权值的一阶逻辑知识库
	+ 基本思想：将一阶逻辑的限制放松，即一个可能世界违反公式越多，其发生的概率越小，但未必为0.
	+ 定义：这定义讲了什么鸡巴？
	+ 我日这都在讲啥啊？？？

	
日你妈，不记笔记了。

## 符号学习

## 神经网络

## 遗传算法

## 强化

## 博弈